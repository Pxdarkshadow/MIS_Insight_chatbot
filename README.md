```
# ğŸ“Š MIS Report Strategy Chatbot

A lightweight **offline desktop chatbot** that processes **MIS-generated PDF reports** and suggests at least **5 actionable strategies**.  
If any other type of input is uploaded, the app simply responds with **â€œNot relevant.â€**

This project runs fully **offline**, using **rule-based logic** for strategy generation.  
Optionally, you can integrate **Ollama** for smarter, locally hosted NLP-based insights.

---

## âœ¨ Features
- âœ… Upload MIS-generated **PDF reports**
- âœ… Extract text locally (no cloud dependencies)
- âœ… Generate **5+ rule-based strategies**
- âœ… Responds *â€œNot relevantâ€* to invalid inputs
- âœ… Simple, clean desktop UI
- âœ… Works fully **offline**
- âš¡ Optional: **Ollama integration** for advanced insights

---

## ğŸ› ï¸ Tech Stack
- **Python** (core logic)
- **Tkinter** (desktop UI)
- **PyMuPDF (fitz)** for PDF text extraction
- **Rule-based strategy engine**
- **[Optional] Ollama** for local NLP

---

## ğŸ“‚ Project Structure
```

mis-chatbot/
â”‚â”€â”€ app.py               # Main app
â”‚â”€â”€ strategies.py        # Rule-based strategies
â”‚â”€â”€ requirements.txt     # Dependencies
â”‚â”€â”€ README.md            # Documentation

````

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/mis-chatbot.git
cd mis-chatbot
````

### 2. Create virtual environment

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the app

```bash
python app.py
```

---

## ğŸ“ Usage

1. Open the app.
2. Click **Upload MIS Report** and select a PDF.
3. If valid, the app will extract text and generate strategies.
4. If not, it will display *â€œNot relevant.â€*

---

## ğŸ”§ Optional: Ollama Integration

If you want to use **Ollama** for smarter suggestions:

1. Install Ollama: [https://ollama.ai](https://ollama.ai)
2. Pull a model (`llama3.1`):

   ```bash
   ollama pull llama3.1
   ```
3. Modify `app.py` to send extracted text to Ollama and display responses.

---

## ğŸ“Œ Example Strategies

* Improve data-driven decision making.
* Optimize resource allocation.
* Identify performance trends.
* Enhance reporting accuracy.
* Automate repetitive tasks.

---

## ğŸ“¦ Build as Executable

You can package the app as a `.exe` (Windows) or `.app` (Mac) with **PyInstaller**:

```bash
pyinstaller --onefile --noconsole app.py
```

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to improve.

---

## ğŸ“œ License

MIT License â€“ Free to use and modify.

```
